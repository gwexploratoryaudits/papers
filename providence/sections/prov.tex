In this section we motivate and introduce the stopping condition of \Providence.

\subsection{Motivation}
\label{sec:prov_motivation}
The \Minerva stopping condition tests the tail ratios of the probability distributions\footnote{given the alternate and null hypotheses respectively} of winner votes $K_j$ in round $j$. Note that these distributions are not conditioned on $k_{j-1}$. Thus each may be viewed as a weighted average of the corresponding conditional distributions---each conditioned on a possible value of $K_{j-1}$, with the weights corresponding to the probabilities of drawing that value of $K_{j-1}$. (See \cite{usenix_minerva} for more details). 

The proof of \Minerva's risk-limiting property relies on the fact that, at every stopping point, the tail of the probability distribution function given $H_0$ is at most $\alpha$ times that given $H_a$. However, because these distributions are averaged over the various values of $K_{j-1}$, this approach to the proof works only if $n_j$ is the same for all values of $K_{j-1}$. If not, the average distribution will not correctly represent the distribution of $K_j$. 

For example, if the current sample is used to determine a next round size of a certain fixed stopping probability, small values of $K_{j-1}$ would be followed by larger values of $n_j$.  In this case, the pdf for the small values of $K_{j-1}$ should not contribute to the average distribution function of $K_j$ for smaller values of $n_j$. This is the reason why the round schedule is predetermined for \Minerva, in order to ensure in an enforceable manner that all values of $k_{j-1}$ lead to the same value of $n_j$ if the audit does not stop in round $j-1$. 

For the \Providence audit we test the tail ratios of the distributions conditioned on $k_{j-1}$ and multiplied by the weighting factor. That is, we test this tail ratio separately for each weighted distribution corresponding to each possible value of $K_{j-1}$. Because of this, we no longer require that all values of $k_{j-1}$ should be followed by the same values of $n_j$ if the audit does not stop in round $j-1$. This results in a great deal of flexibility in multiple round audits. 

\subsection{Definition}
\label{sec:prov_def}
\begin{definition}[$(\alpha,p_a, p_0,k_{j-1},n_{j-1},n_j)$-\Providence]
    \label{def:minervatwo}
    For cumulative round size $n_i$ for round $i$ and a cumulative $k_i$ ballots for the reported winner found in round $i$, the \R \Providence stopping rule for the $j^{th}$ round is:
$$
\mathcal{A}(X_{j})=  \left\{ \begin{array}{ll} \text{Correct} ~~~~ \omega_{j}(k_{j}, k_{j-1}, p_a, p_0, n_j, n_{j-1}) \geq \frac{1}{\alpha}\\
        % & \\
        % incorrect& ~~~ \sigma_n < \frac{\beta}{1-\alpha} \\
        % & \\
        Undetermined ~~else \\
    \end{array}
    \right .
$$
where $\omega _{1}\triangleq \tau_{1}$ and for $j\ge 2$, we define $\omega _{j}$ as follows:
\begin{equation}
    \begin{aligned}
    \omega_{j}(k_{j}, k_{j-1}, p_a, p_0, n_{j}, n_{j-1})
    \triangleq\\
    \sigma(k_{j-1},p_a,p_0,n_{j-1})\cdot \tau_1(k_{j}-k_{j-1},p_a,p_0,n_j-n_{j-1})
    \end{aligned}
\end{equation}
\end{definition}

Notice that for $j\ge 2$, unlike $\tau_j$, computing $\omega_j$ requires no convolution and is hence computationally considerably more efficient. 

\subsection{Proof of Risk-Limiting Property}
\label{sec:proof}
We now prove that \Providence is risk-limiting using lemmas from basic algebra in Appendix~\ref{sec:proofs}.

\begin{theorem}
\label{thm:minerva2_is_rla_new}
An $(\alpha,p_a, p_0,k_{j-1},n_{j-1},n_j)$-\Providence audit is an
$\alpha$-RLA.
\end{theorem}
\begin{proof}
Let $\mathcal{A}=(\alpha,p_a, p_0,k_{j-1},n_{j-1},n_j)$-\Providence.
Let $\bm{n_j}$ be the cumulative round sizes used in this
audit, with corresponding cumulative tallies of
ballots for the reported winner $\bm{k_j}$.
For round $j=1$, by Definitions \ref{def:minervatwo}
and \ref{def:minerva_ratio}, we see that
the $\mathcal{A}=\text{Correct}$ (the audit stops) only when
$$
\tau_1(k_{1},p_a,p_0,n_1)\\
=\frac{Pr[K_{1} \geq k_{1} \mid H_a, n_1]}{Pr[K_{1} \geq k_{1} \mid H_0, n_1]}
\ge \frac{1}{\alpha}.
$$
By Lemma \ref{lemma:minerva2_kmin_exists}, we see that this
is equivalent to the following:
$$
\frac{Pr[K_{1} \geq k_{min,1} \mid H_a, n_1]}{Pr[K_{1} \geq k_{min, 1} \mid H_0, n_1]}
\ge \frac{1}{\alpha}.
$$

For any round $j\ge 2$, by Definition \ref{def:minervatwo}
and Lemma \ref{lemma:minerva2_kmin_exists},
$\mathcal{A}=\text{Correct}$ (the audit stops) only when
\begin{equation*}
\begin{aligned}
\omega_{j}(k_{j}, k_{j-1}, p_a, p_0, n_{j}, n_{j-1}, \alpha )\triangleq\\
\sigma(k_{j-1},p_a,p_0,n_{j-1})\cdot \tau_1(k_{j}-k_{j-1},p_a,p_0,n_j-n_{j-1})
\ge \frac{1}{\alpha}.
\end{aligned}
\end{equation*}
%Let $d_j=k_j-k_{j-1}$ be shorthand for the new draw.
%could do this for simpler notation^
By Lemma \ref{lemma:any_ratio_is_sigma_simple}
and Definition \ref{def:minerva_ratio}, this is equivalent to
$$
\frac{\Pr[K_{j-1} = {k_{j-1}} \mid H_a, n_{j-1}]\cdot Pr[K_{j} \ge k_{j} \mid {k_{j-1}}, H_a, n_{j-1}, n_{j}]}{\Pr[K_{j-1} = {k_{j-1}} \mid H_0, n_{j-1}]\cdot Pr[K_{j} \ge k_{j} \mid {k_{j-1}}, H_0, n_{j-1}, n_{j}]}\ge \frac{1}{\alpha}.
$$
By Lemma~\ref{lemma:minerva2_kmin_exists} and Definition~\ref{def:minervatwo},
we see that there exists a $k_{min, j} = k_{min, j, n_{j-1}, n_j}^{p_a, p_0, k_{j-1}} \leq k_j$ 
%$k_{min, j}\le k_j$ 
for which
$$
\frac{\Pr[K_{j-1} = {k_{j-1}} \mid H_a, n_{j-1}]\cdot Pr[K_{j} \ge k_{j} \mid {k_{j-1}}, H_a, n_{j-1}, n_{j}]}{\Pr[K_{j-1} = {k_{j-1}} \mid H_0, n_{j-1}]\cdot Pr[K_{j} \ge k_{j} \mid {k_{j-1}}, H_0, n_{j-1}, n_{j}]}\ge
$$
$$
\frac{\Pr[K_{j-1} = {k_{j-1}} \mid H_a, n_{j-1}]\cdot Pr[K_{j} \ge k_{min, j} \mid {k_{j-1}}, H_a, n_{j-1}, n_{j}]}{\Pr[K_{j-1} = {k_{j-1}} \mid H_0, n_{j-1}]\cdot Pr[K_{j} \ge k_{min, j} \mid {k_{j-1}}, H_0, n_{j-1}, n_{j}]} \ge 
\frac{1}{\alpha}
$$
%Equivalently,
%$$
%\frac{Pr[K_{j} \ge k_{min, j}\wedge K_{j-1} = k_{j-1} \mid n_{j}^*, k_{j-2}^*, H_a]}{Pr[K_{j}\ge k_{min, j} \wedge K_{j-1} = k_{j-1} \mid n_{j}^*, k_{j-2}^*, H_0]}\ge \frac{1}{\alpha}.
%$$
%Taking the sum over all possible rounds and corresponding preceding values
%of $k$, we get
% Taking the sum over all possible audit histories, we get
It can be rewritten as
$$
\frac{\Pr[K_{j-1} = {k_{j-1}} \mid H_a, n_{j-1}]\cdot \sum_{{k} = k_{min, j}}^{n_j} Pr[K_{j} = k \mid {k_{j-1}}, H_a, n_{j-1}, n_{j}]}{\Pr[K_{j-1} = {k_{j-1}} \mid H_0, n_{j-1}]\cdot \sum_{{k} = k_{min, j}}^{n_j} Pr[K_{j} = k \mid {k_{j-1}}, H_0, n_{j-1}, n_{j}]}\ge \frac{1}{\alpha}.
$$
Finally, because the total probability of stopping the audit under
the alternative hypothesis is less than 1, we get
$$
\frac{Pr[\mathcal{A}=\text{Correct} \mid H_a]}{Pr[\mathcal{A}=\text{Correct} \mid H_0]}\ge \frac{1}{\alpha}
$$
$$
Pr[\mathcal{A}=\text{Correct} \mid H_0]
\le
Pr[\mathcal{A}=\text{Correct} \mid H_a] \cdot \alpha
\le
\alpha.
$$
\end{proof}

\subsection{Resistance to an adversary choosing round sizes}
\label{sec:adversary}
% Filip TBD
\input{sections/adversary}
